{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21bc14ec-2624-4dad-ae2d-323b8e7284f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9542 entries, 0 to 9550\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   restaurant_name  9542 non-null   object \n",
      " 1   city             9542 non-null   object \n",
      " 2   locality         9542 non-null   object \n",
      " 3   cuisines         9542 non-null   object \n",
      " 4   cost             9542 non-null   int64  \n",
      " 5   currency         9542 non-null   object \n",
      " 6   price_range      9542 non-null   int64  \n",
      " 7   rating           9542 non-null   float64\n",
      " 8   votes            9542 non-null   int64  \n",
      " 9   cost_bucket      9542 non-null   object \n",
      " 10  primary_cuisine  9542 non-null   object \n",
      "dtypes: float64(1), int64(3), object(7)\n",
      "memory usage: 894.6+ KB\n",
      "None\n",
      "          restaurant_name              city  \\\n",
      "0        Le Petit Souffle       makati city   \n",
      "1        Izakaya Kikufuji       makati city   \n",
      "2  Heat - Edsa Shangri-La  mandaluyong city   \n",
      "3                    Ooma  mandaluyong city   \n",
      "4             Sambo Kojin  mandaluyong city   \n",
      "\n",
      "                                     locality  \\\n",
      "0   Century City Mall, Poblacion, Makati City   \n",
      "1  Little Tokyo, Legaspi Village, Makati City   \n",
      "2  Edsa Shangri-La, Ortigas, Mandaluyong City   \n",
      "3      SM Megamall, Ortigas, Mandaluyong City   \n",
      "4      SM Megamall, Ortigas, Mandaluyong City   \n",
      "\n",
      "                           cuisines  cost          currency  price_range  \\\n",
      "0        french, japanese, desserts  1100  Botswana Pula(P)            3   \n",
      "1                          japanese  1200  Botswana Pula(P)            3   \n",
      "2  seafood, asian, filipino, indian  4000  Botswana Pula(P)            4   \n",
      "3                   japanese, sushi  1500  Botswana Pula(P)            4   \n",
      "4                  japanese, korean  1500  Botswana Pula(P)            4   \n",
      "\n",
      "   rating  votes cost_bucket primary_cuisine  \n",
      "0     4.8    314        High          french  \n",
      "1     4.5    591        High        japanese  \n",
      "2     4.4    270        High         seafood  \n",
      "3     4.9    365        High        japanese  \n",
      "4     4.8    229        High        japanese  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the dataset with proper encoding\n",
    "df = pd.read_csv('zomato.csv', encoding='latin1')\n",
    "\n",
    "# Step 2: Normalize column names (lowercase, replace spaces with underscores)\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Step 3: Drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Step 4: Drop irrelevant columns if present\n",
    "columns_to_drop = [\n",
    "    'restaurant_id', 'country_code', 'address', 'locality_verbose',\n",
    "    'longitude', 'latitude', 'has_table_booking', 'has_online_delivery',\n",
    "    'is_delivering_now', 'switch_to_order_menu', 'rating_color', 'rating_text'\n",
    "]\n",
    "df.drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)\n",
    "\n",
    "# Step 5: Rename columns for easier handling \n",
    "df.rename(columns={\n",
    "    'average_cost_for_two': 'cost',\n",
    "    'aggregate_rating': 'rating'\n",
    "}, inplace=True)\n",
    "\n",
    "# Step 6: Clean cost and rating columns\n",
    "df['cost'] = pd.to_numeric(df['cost'], errors='coerce')\n",
    "df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "\n",
    "# Step 7: Fill missing numeric values with column-wise mean\n",
    "df.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "# Step 8: Drop rows with missing critical text fields\n",
    "df.dropna(subset=['cuisines', 'city'], inplace=True)\n",
    "\n",
    "# Step 9: Normalize text columns\n",
    "df['cuisines'] = df['cuisines'].str.lower().str.strip()\n",
    "df['city'] = df['city'].str.lower().str.strip()\n",
    "df['restaurant_name'] = df['restaurant_name'].str.strip()\n",
    "\n",
    "# Step 10: Feature engineering\n",
    "\n",
    "# Cost bucket\n",
    "def cost_bucket(cost):\n",
    "    if cost < 300:\n",
    "        return 'Low'\n",
    "    elif cost < 700:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "df['cost_bucket'] = df['cost'].apply(cost_bucket)\n",
    "\n",
    "# Extract primary cuisine\n",
    "df['primary_cuisine'] = df['cuisines'].apply(lambda x: x.split(',')[0] if isinstance(x, str) else x)\n",
    "\n",
    "# Round rating\n",
    "df['rating'] = df['rating'].round(1)\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv('zomato_cleaned.csv', index=False)\n",
    "\n",
    "# Check result\n",
    "print(df.info())\n",
    "print(df.head())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3789903f-d483-4983-a35b-b414d96a38b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_rank(df, selected_cuisines, budget_range, selected_location, top_n=10):\n",
    "\n",
    "    \"\"\"\n",
    "    Filters and ranks restaurants based on user preferences.\n",
    "    Parameters:\n",
    "    - df (DataFrame): Cleaned restaurant dataset.\n",
    "    - selected_cuisines (list of str): User's preferred cuisines.\n",
    "    - budget_range (str): One of ['Low', 'Medium', 'High'].\n",
    "    - selected_location (str): Preferred city or location.\n",
    "    - top_n (int): Number of top results to return.\n",
    "    Returns:\n",
    "    - DataFrame with top N recommendations and explanation column.\n",
    "    \"\"\"\n",
    "    # --- Filtering ---\n",
    "    filtered_df = df[\n",
    "        (df['cost_bucket'] == budget_range) &\n",
    "        (df['city'].str.contains(selected_location.lower(), na=False)) &\n",
    "        (df['primary_cuisine'].isin([c.lower() for c in selected_cuisines]))\n",
    "    ]\n",
    "\n",
    "    if filtered_df.empty:\n",
    "        return pd.DataFrame(columns=['restaurant_name', 'primary_cuisine', 'cost', 'rating', 'votes', 'explanation'])\n",
    "    # --- Ranking ---\n",
    "    # Normalize 'rating' and 'votes' to bring them to a common scale\n",
    "    filtered_df = filtered_df.copy()\n",
    "    filtered_df['norm_rating'] = filtered_df['rating'] / 5.0\n",
    "    filtered_df['norm_votes'] = filtered_df['votes'] / (filtered_df['votes'].max() if filtered_df['votes'].max() != 0 else 1)\n",
    "\n",
    "    # Weighted score (60% rating, 40% votes)\n",
    "\n",
    "    filtered_df['score'] = (0.6 * filtered_df['norm_rating']) + (0.4 * filtered_df['norm_votes'])\n",
    "\n",
    "    # Sort by score\n",
    "    ranked_df = filtered_df.sort_values(by='score', ascending=False).head(top_n)\n",
    "    # --- Explainability ---\n",
    "    ranked_df['explanation'] = ranked_df.apply(\n",
    "        lambda row: f\"Matched on {row['primary_cuisine'].title()} cuisine, {budget_range} budget, and rating {row['rating']}\",\n",
    "        axis=1\n",
    "    )\n",
    "    # Select relevant columns\n",
    "    result = ranked_df[[\n",
    "        'restaurant_name', 'primary_cuisine', 'cost', 'rating', 'votes', 'city', 'explanation'\n",
    "    ]].reset_index(drop=True)\n",
    "    return result\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "343670a6-83ad-40c1-855c-f4f6af82287c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              restaurant_name primary_cuisine  cost  rating  votes       city  \\\n",
      "0                Munch Nation         chinese   350     3.8    727  new delhi   \n",
      "1                   Kennedy's         chinese   400     4.1    491  new delhi   \n",
      "2                   Wow! Momo         chinese   350     3.4    491  new delhi   \n",
      "3  Jughead's Fast Food Corner         chinese   500     3.6    438  new delhi   \n",
      "4                Scorpio Cafe         chinese   400     3.7    410  new delhi   \n",
      "5                    Nikashee         chinese   600     3.7    408  new delhi   \n",
      "6                 Happy Hakka         chinese   650     3.8    312  new delhi   \n",
      "7                     Hawkers         chinese   600     3.4    398  new delhi   \n",
      "8                   Casa Asia         chinese   650     3.8    306  new delhi   \n",
      "9                 Happy Hakka         chinese   650     3.7    270  new delhi   \n",
      "\n",
      "                                         explanation  \n",
      "0  Matched on Chinese cuisine, Medium budget, and...  \n",
      "1  Matched on Chinese cuisine, Medium budget, and...  \n",
      "2  Matched on Chinese cuisine, Medium budget, and...  \n",
      "3  Matched on Chinese cuisine, Medium budget, and...  \n",
      "4  Matched on Chinese cuisine, Medium budget, and...  \n",
      "5  Matched on Chinese cuisine, Medium budget, and...  \n",
      "6  Matched on Chinese cuisine, Medium budget, and...  \n",
      "7  Matched on Chinese cuisine, Medium budget, and...  \n",
      "8  Matched on Chinese cuisine, Medium budget, and...  \n",
      "9  Matched on Chinese cuisine, Medium budget, and...  \n"
     ]
    }
   ],
   "source": [
    "user_cuisines = ['Indian', 'Chinese']\n",
    "\n",
    "user_budget = 'Medium'\n",
    "\n",
    "user_location = 'Delhi'\n",
    "\n",
    "recommendations = filter_and_rank(df, user_cuisines, user_budget, user_location)\n",
    "\n",
    "print(recommendations)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ee5d5e0-3f95-4e69-9f99-4a8161cb94df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Input DataFrame for Recommender (Head) ---\n",
      "  restaurant_name                   cuisines  cost  rating  votes    city  \\\n",
      "0    Pizza Heaven             italian, pizza   700     4.1    550  mumbai   \n",
      "1      Curry King      north indian, mughlai  1200     4.5   1100  mumbai   \n",
      "2     Burger Barn           american, burger   500     3.9    320   delhi   \n",
      "3     Sushi World            japanese, sushi  1500     4.2    780  mumbai   \n",
      "4       Taco Town  mexican, fast food, spicy   350     3.8    210   delhi   \n",
      "\n",
      "          locality cost_bucket primary_cuisine  \n",
      "0           bandra      medium         italian  \n",
      "1          andheri        high    north indian  \n",
      "2  connaught place      medium        american  \n",
      "3             juhu        high        japanese  \n",
      "4            saket      medium         mexican  \n",
      "\n",
      "Input DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   restaurant_name  5 non-null      object \n",
      " 1   cuisines         5 non-null      object \n",
      " 2   cost             5 non-null      int64  \n",
      " 3   rating           5 non-null      float64\n",
      " 4   votes            5 non-null      int64  \n",
      " 5   city             5 non-null      object \n",
      " 6   locality         5 non-null      object \n",
      " 7   cost_bucket      5 non-null      object \n",
      " 8   primary_cuisine  5 non-null      object \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 492.0+ bytes\n",
      "\n",
      "--- Test Case 1: Specific Search (Expected Match) ---\n",
      "  restaurant_name               cuisines  cost  rating  score  \\\n",
      "1      Curry King  north indian, mughlai  1200     4.5   0.93   \n",
      "\n",
      "                                         explanation  \n",
      "1  Matched on North Indian cuisine and high budge...  \n",
      "\n",
      "--- Test Case 2: Cuisine with 'spicy' (Substring Match Test) ---\n",
      "  restaurant_name                   cuisines  cost  rating  score  \\\n",
      "4       Taco Town  mexican, fast food, spicy   350     3.8  0.832   \n",
      "\n",
      "                                         explanation  \n",
      "4  Matched on Mexican cuisine and medium budget (...  \n",
      "\n",
      "--- Test Case 3: No Matches Expected ---\n",
      "No restaurants matched the filter criteria.\n",
      "No recommendations found for Test Case 3 (as expected).\n",
      "Empty recommendations DataFrame correctly includes 'explanation' column.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class RestaurantRecommender:\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Initialize the recommender with a preprocessed dataframe\n",
    "        Args:\n",
    "            df: Pandas DataFrame with cleaned restaurant data from your Step 1\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        required_cols = ['restaurant_name', 'cuisines', 'cost', 'rating',\n",
    "                         'votes', 'city', 'cost_bucket', 'primary_cuisine']\n",
    "\n",
    "        # 'locality' is often used for location, check if it's in your df\n",
    "        if 'locality' not in df.columns:\n",
    "            print(\"Warning: 'locality' column not found in the input DataFrame. Location filtering will only use 'city'.\")\n",
    "  \n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Input DataFrame is missing required columns for the recommender: {missing_cols}. \"\n",
    "                             \"Please ensure your Step 1 preprocessing produces these columns.\")\n",
    "\n",
    "    def filter_restaurants(self, cuisines=None, location=None, budget=None):\n",
    "        filtered_df = self.df.copy()\n",
    "\n",
    "        # Filter by cuisine\n",
    "        if cuisines and len(cuisines) > 0:\n",
    "            cuisines_lower = [cuisine.lower().strip() for cuisine in cuisines]\n",
    "            # Ensure 'cuisines' column in df is string type for '.apply'\n",
    "            cuisine_mask = filtered_df['cuisines'].astype(str).apply(\n",
    "                lambda x: any(cuisine in x for cuisine in cuisines_lower)\n",
    "            )\n",
    "            filtered_df = filtered_df[cuisine_mask]\n",
    "\n",
    "        # Filter by location\n",
    "        if location:\n",
    "            location_lower = location.lower().strip()\n",
    "            # Ensure 'city' column in df is string type\n",
    "            city_mask = filtered_df['city'].astype(str).str.contains(location_lower, na=False, case=False)\n",
    "            locality_mask = pd.Series(False, index=filtered_df.index) # Default to False\n",
    "\n",
    "            if 'locality' in filtered_df.columns:\n",
    "                # Ensure 'locality' column in df is string type\n",
    "                locality_mask = filtered_df['locality'].astype(str).str.contains(location_lower, na=False, case=False)\n",
    "            \n",
    "            combined_location_mask = city_mask | locality_mask\n",
    "            filtered_df = filtered_df[combined_location_mask]\n",
    "\n",
    "        # Filter by budget\n",
    "        if budget:\n",
    "            if isinstance(budget, str):\n",
    "                budget_lower = budget.lower().strip()\n",
    "                # Ensure 'cost_bucket' column in df is string type and lowercased\n",
    "                filtered_df = filtered_df[filtered_df['cost_bucket'].astype(str).str.lower() == budget_lower]\n",
    "            elif isinstance(budget, (list, tuple)) and len(budget) == 2:\n",
    "                min_cost, max_cost = budget\n",
    "                # Ensure 'cost' is numeric\n",
    "                filtered_df = filtered_df[(pd.to_numeric(filtered_df['cost'], errors='coerce') >= min_cost) &\n",
    "                                         (pd.to_numeric(filtered_df['cost'], errors='coerce') <= max_cost)]\n",
    "        return filtered_df\n",
    "\n",
    "    def calculate_scores(self, filtered_df, rating_weight=0.7, votes_weight=0.3):\n",
    "        if filtered_df.empty:\n",
    "            filtered_df['score'] = pd.Series(dtype='float64') # Ensure 'score' column exists\n",
    "            return filtered_df\n",
    "\n",
    "        # Ensure 'rating' is numeric and handle potential NaNs\n",
    "        ratings_numeric = pd.to_numeric(filtered_df['rating'], errors='coerce').fillna(0)\n",
    "        max_rating = 5.0 # Assuming a 0-5 scale for Zomato ratings\n",
    "        normalized_ratings = ratings_numeric / max_rating\n",
    "        normalized_ratings = normalized_ratings.clip(0, 1)\n",
    "\n",
    "        # Ensure 'votes' is numeric and handle potential NaNs\n",
    "        if 'votes' in filtered_df.columns:\n",
    "            votes_numeric = pd.to_numeric(filtered_df['votes'], errors='coerce').fillna(0)\n",
    "            log_votes = np.log1p(votes_numeric)\n",
    "            max_log_votes = log_votes.max()\n",
    "            if max_log_votes > 0:\n",
    "                normalized_votes = log_votes / max_log_votes\n",
    "            else:\n",
    "                normalized_votes = pd.Series(0.0, index=filtered_df.index)\n",
    "        else:\n",
    "            print(\"Warning: 'votes' column not found for scoring. Votes weight will effectively be 0.\")\n",
    "            normalized_votes = pd.Series(0.0, index=filtered_df.index)\n",
    "\n",
    "        filtered_df['score'] = (\n",
    "            normalized_ratings * rating_weight +\n",
    "            normalized_votes * votes_weight\n",
    "        )\n",
    "        return filtered_df\n",
    "\n",
    "    def rank_restaurants(self, filtered_df, top_n=10):\n",
    "        if filtered_df.empty or 'score' not in filtered_df.columns:\n",
    "            return filtered_df\n",
    "\n",
    "        sorted_df = filtered_df.sort_values(by='score', ascending=False)\n",
    "        return sorted_df.head(top_n)\n",
    "\n",
    "    def generate_explanation(self, restaurant_row):\n",
    "        try:\n",
    "            # Use .get() for safer access, provide defaults if key might be missing\n",
    "            cuisine_val = restaurant_row.get('primary_cuisine', 'N/A')\n",
    "            cost_bucket_val = restaurant_row.get('cost_bucket', 'N/A')\n",
    "            cost_val = restaurant_row.get('cost', 0)\n",
    "            rating_val = restaurant_row.get('rating', 0)\n",
    "            votes_val = restaurant_row.get('votes', 0)\n",
    "\n",
    "            explanation = f\"Matched on {str(cuisine_val).title()} cuisine\"\n",
    "            explanation += f\" and {str(cost_bucket_val).lower()} budget (₹{float(cost_val):.0f} for two)\"\n",
    "            explanation += f\" with {float(rating_val):.1f}/5 rating\"\n",
    "            if votes_val > 0:\n",
    "                explanation += f\" based on {int(votes_val)} votes.\"\n",
    "            else:\n",
    "                explanation += \".\"\n",
    "        except Exception as e:\n",
    "            explanation = \"Could not generate detailed explanation due to an issue with restaurant data.\"\n",
    "            print(f\"Error generating explanation for a row: {e}. Row data: {restaurant_row.to_dict()}\")\n",
    "        return explanation\n",
    "\n",
    "    def filter_and_rank(self, cuisines=None, location=None, budget=None, top_n=10):\n",
    "\n",
    "        filtered_df = self.filter_restaurants(cuisines, location, budget)\n",
    "\n",
    "        # Define the columns expected for the final output, especially for printing or UI\n",
    "        # This helps ensure the DataFrame structure is consistent even if empty.\n",
    "        # It should include all columns from the original df that you want to keep, plus 'score' and 'explanation'.\n",
    "        final_output_columns = list(self.df.columns)\n",
    "        if 'score' not in final_output_columns:\n",
    "            final_output_columns.append('score')\n",
    "        if 'explanation' not in final_output_columns:\n",
    "            final_output_columns.append('explanation')\n",
    "\n",
    "\n",
    "        if filtered_df.empty:\n",
    "            print(\"No restaurants matched the filter criteria.\")\n",
    "            # Return an empty DataFrame but with all expected columns (including 'score' and 'explanation')\n",
    "            return pd.DataFrame(columns=final_output_columns)\n",
    "\n",
    "        scored_df = self.calculate_scores(filtered_df)\n",
    "        ranked_df = self.rank_restaurants(scored_df, top_n)\n",
    "\n",
    "        if not ranked_df.empty:\n",
    "            ranked_df['explanation'] = ranked_df.apply(self.generate_explanation, axis=1)\n",
    "        else:\n",
    "            # If ranked_df is empty (e.g. top_n=0 or some other issue), create an empty DF with correct columns\n",
    "            return pd.DataFrame(columns=final_output_columns)\n",
    "            \n",
    "        # Ensure the final ranked_df has all the expected columns.\n",
    "        # This is mostly for consistency if some columns were dropped during intermediate steps,\n",
    "        # though current logic shouldn't do that.\n",
    "        # Reindex can add missing columns with NaN.\n",
    "        # return ranked_df.reindex(columns=final_output_columns)\n",
    "        return ranked_df\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# EXAMPLE USAGE (Assuming 'df' is your preprocessed DataFrame from Step 1)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# --- YOU NEED TO LOAD/CREATE YOUR 'df' HERE using your Step 1 code ---\n",
    "# Example:\n",
    "# df = pd.read_csv('zomato_cleaned.csv') # Load your cleaned data\n",
    "# Or, if your Step 1 function is `my_step1_preprocess()`:\n",
    "# df = my_step1_preprocess('zomato.csv')\n",
    "\n",
    "# For demonstration, let's create a minimal dummy 'df' that your Step 1 might produce\n",
    "# This dummy DF must have the columns checked in `Recommender.__init__`\n",
    "# and columns used by the filtering/scoring logic.\n",
    "_data_for_dummy_df = {\n",
    "    'restaurant_name': ['Pizza Heaven', 'Curry King', 'Burger Barn', 'Sushi World', 'Taco Town'],\n",
    "    'cuisines': ['italian, pizza', 'north indian, mughlai', 'american, burger', 'japanese, sushi', 'mexican, fast food, spicy'],\n",
    "    'cost': [700, 1200, 500, 1500, 350],\n",
    "    'rating': [4.1, 4.5, 3.9, 4.2, 3.8],\n",
    "    'votes': [550, 1100, 320, 780, 210],\n",
    "    'city': ['mumbai', 'mumbai', 'delhi', 'mumbai', 'delhi'],\n",
    "    'locality': ['bandra', 'andheri', 'connaught place', 'juhu', 'saket'], # Optional\n",
    "    'cost_bucket': ['medium', 'high', 'medium', 'high', 'medium'], # Make sure this matches your Step 1 output\n",
    "    'primary_cuisine': ['italian', 'north indian', 'american', 'japanese', 'mexican']\n",
    "}\n",
    "df = pd.DataFrame(_data_for_dummy_df)\n",
    "# --- End of dummy df creation ---\n",
    "\n",
    "if df.empty:\n",
    "    print(\"The input DataFrame 'df' is empty. Cannot proceed with recommender.\")\n",
    "else:\n",
    "    print(\"\\n--- Input DataFrame for Recommender (Head) ---\")\n",
    "    print(df.head())\n",
    "    print(f\"\\nInput DataFrame info:\")\n",
    "    df.info()\n",
    "\n",
    "\n",
    "    recommender = RestaurantRecommender(df)\n",
    "\n",
    "    print(\"\\n--- Test Case 1: Specific Search (Expected Match) ---\")\n",
    "    recommendations1 = recommender.filter_and_rank(\n",
    "        cuisines=['north indian', 'mughlai'],\n",
    "        location='mumbai',\n",
    "        budget='High', # Matches 'high' in cost_bucket\n",
    "        top_n=5\n",
    "    )\n",
    "    if not recommendations1.empty:\n",
    "        # Select only relevant columns for concise printing\n",
    "        cols_to_print = ['restaurant_name', 'cuisines', 'cost', 'rating', 'score', 'explanation']\n",
    "        # Ensure all selected columns exist in recommendations1 before printing\n",
    "        existing_cols_to_print = [col for col in cols_to_print if col in recommendations1.columns]\n",
    "        print(recommendations1[existing_cols_to_print])\n",
    "    else:\n",
    "        print(\"No recommendations found for Test Case 1.\")\n",
    "\n",
    "    print(\"\\n--- Test Case 2: Cuisine with 'spicy' (Substring Match Test) ---\")\n",
    "    recommendations2 = recommender.filter_and_rank(\n",
    "        cuisines=['spicy'], # Should match 'mexican, fast food, spicy'\n",
    "        location='delhi',\n",
    "        top_n=3\n",
    "    )\n",
    "    if not recommendations2.empty:\n",
    "        cols_to_print = ['restaurant_name', 'cuisines', 'cost', 'rating', 'score', 'explanation']\n",
    "        existing_cols_to_print = [col for col in cols_to_print if col in recommendations2.columns]\n",
    "        print(recommendations2[existing_cols_to_print])\n",
    "\n",
    "    else:\n",
    "        print(\"No recommendations found for Test Case 2.\")\n",
    "\n",
    "    print(\"\\n--- Test Case 3: No Matches Expected ---\")\n",
    "    recommendations3 = recommender.filter_and_rank(\n",
    "        cuisines=['ethiopian'],\n",
    "        location='moonbase alpha',\n",
    "        budget='low',\n",
    "        top_n=5\n",
    "    )\n",
    "    if not recommendations3.empty:\n",
    "        cols_to_print = ['restaurant_name', 'cuisines', 'cost', 'rating', 'score', 'explanation']\n",
    "        existing_cols_to_print = [col for col in cols_to_print if col in recommendations3.columns]\n",
    "        print(recommendations3[existing_cols_to_print])\n",
    "    else:\n",
    "        print(\"No recommendations found for Test Case 3 (as expected).\")\n",
    "        # Check if the empty DF has the 'explanation' column:\n",
    "        if 'explanation' in recommendations3.columns:\n",
    "            print(\"Empty recommendations DataFrame correctly includes 'explanation' column.\")\n",
    "        else:\n",
    "            print(\"Error: Empty recommendations DataFrame MISSING 'explanation' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849dc473-c322-49e7-b10b-2792477cc911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
